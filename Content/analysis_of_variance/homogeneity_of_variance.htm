<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd">
    <head><title>Homogeneity or Equality of Variance - StatsDirect</title>
        <link rel="StyleSheet" href="../resources/Stylesheets/STATSDIRECT.css" type="text/css" />
        <script type="text/javascript">
        </script>
        <meta name="description" content="Testing for homogeneity or equality of variance in StatsDirect statistical software." />
    </head>
    <body>
        <h1>
            <MadCap:keyword term="ANOVA: Homogeneity;Bartlett's test;Homogeneity of variance;Equality of variance;Levene's test;Squared ranks test" />
            Equality (Homogeneity) of Variance</h1>
        <p>&#160;</p>
        <p>Menu locations:</p>
        <p><b>Analysis_Analysis of Variance_Oneway</b>
        </p>
        <p><b>Analysis_Analysis of Variance_Kruskal-Wallis)</b>.</p>
        <p>&#160;</p>
        <p>
            StatsDirect provides parametric (Bartlet and Levene) and nonparametric (squared ranks) tests for equality/homogeneity of variance.</p>
        <p>&#160;</p>
        <p>
            Most commonly used statistical hypothesis tests, such as t tests, compare means or other measures of location. Some studies need to compare variability also. Equality of variance tests can be used on their own for this purpose but they are often used alongside other methods (e.g. analysis of variance) to support assumptions made about variance. For this reason, StatsDirect presents equality of variance tests with analysis of variance.</p>
        <p>&#160;</p>
        <p><u style="font-weight: bold;">Bartlett and Levene (parametric) tests</u>
        </p>
        <p>&#160;</p>
        <p><u>Two samples</u>
        </p>
        <p>Use the <a href="../parametric_methods/f_variance_ratio.htm">F test</a> to compare the variances of two random samples from a normal distribution. Note that the F test is quite sensitive to departures from normality; if you have any doubt then please use the nonparametric equivalent described below.</p>
        <p>&#160;</p>
        <p><u>More than two samples (Levene)</u>
        </p>
        <p>
            StatsDirect gives Levene's test as an option with <a href="one_way.htm">One Way Analysis of Variance</a>.</p>
        <p>&#160;</p>
        <p>The W50 definition of Levene test statistic (<a href="../references/reference_list.htm">Brown and Forsythe, 1974</a>) is used; this is essentially a one way analysis of variance on the absolute (unsigned) values of the deviations of observations from their group medians.</p>
        <p>&#160;</p>
        <p>
            Levene's test assumes only that your data form random samples from continuous distributions. If you are in any doubt about this, use the squared ranks test presented below, it is generally more robust.</p>
        <p>&#160;</p>
        <p><u>More than two samples (Bartlett)</u>
        </p>
        <p>StatsDirect gives Bartlett's test as an option with <a href="one_way.htm">One Way Analysis of Variance</a>.</p>
        <p>&#160;</p>
        <p>Bartlett's test assesses equality of the variances of more than two samples from a normal distribution (<a href="../references/reference_list.htm">Armitage and Berry, 1994</a>).</p>
        <p>&#160;</p>
        <p>Please note that Bartlett's test is not reliable with moderate departures from normality; use Levene's test as an alternative routinely. Bartlett's test is included here solely for the purpose of continuity with textbooks.</p>
        <p>&#160;</p>
        <p><u style="font-weight: bold;">Squared Ranks (nonparametric) test</u>
        </p>
        <p>StatsDirect gives the squared ranks test as an option in the <a href="../nonparametric_methods/kruskal_wallis.htm">Kruskal-Wallis test</a>.</p>
        <p>&#160;</p>
        <p>The squared ranks test can be used to assess equality of variance across two or more independent, random samples which have been measured using a scale that is at least interval (<a href="../references/reference_list.htm">Conover, 1999</a>).</p>
        <p>&#160;</p>
        <p>When you analyse more than two samples with the squared ranks test, StatsDirect performs an automatic comparison of all possible pair-wise contrasts as described by <a href="../references/reference_list.htm">Conover (1999)</a>.</p>
        <p>&#160;</p>
        <p>Assumptions of the squared ranks test:</p>
        <ul type="disc">
            <li class="p">
                <p>random samples</p>
            </li>
            <li class="p">
                <p>independence within samples</p>
            </li>
            <li class="p">
                <p>mutual independence between samples</p>
            </li>
            <li class="p">
                <p>measurement scale is at least interval</p>
            </li>
        </ul>
        <p>&#160;</p>
        <p><u>Example</u>
        </p>
        <p>From <a href="../references/reference_list.htm">Conover (1999, p. 305)</a>.</p>
        <p>Test workbook (Nonparametric worksheet: Machine X, Machine Y).</p>
        <p>&#160;</p>
        <p>The following data represent the weight of cereal in boxes filled by two different machines X and Y.</p>
        <p>&#160;</p>
        <table cellspacing="0" style="caption-side: top;">
            <col />
            <col />
            <tr>
                <td style="text-align: right;text-decoration: underline;">Machine X</td>
                <td style="text-align: right;text-decoration: underline;">Machine Y</td>
            </tr>
            <tr>
                <td style="text-align: right;">10.8</td>
                <td style="text-align: right;">10.8</td>
            </tr>
            <tr>
                <td style="text-align: right;">11.1</td>
                <td style="text-align: right;">10.5</td>
            </tr>
            <tr>
                <td style="text-align: right;">10.4</td>
                <td style="text-align: right;">11.0</td>
            </tr>
            <tr>
                <td style="text-align: right;">10.1</td>
                <td style="text-align: right;">10.9</td>
            </tr>
            <tr>
                <td style="text-align: right;">11.3</td>
                <td style="text-align: right;">10.8</td>
            </tr>
            <tr>
                <td style="text-align: right;">&#160;</td>
                <td style="text-align: right;">10.7</td>
            </tr>
            <tr>
                <td style="text-align: right;">&#160;</td>
                <td style="text-align: right;">18.8</td>
            </tr>
        </table>
        <p>&#160;</p>
        <p>To analyse these data in StatsDirect you must first prepare them in two workbook columns appropriately labelled. Alternatively, open the test workbook using the file open function of the file menu. Then select Kruskal-Wallis from the Nonparametric section of the analysis menu. Then <a href="../workbook/selecting_data.htm">select</a> the columns marked "Machine X" and "Machine Y" in one selection action. Ignore the Kruskal-Wallis test result and select the squared ranks variance equality test option then click on the calculate button.</p>
        <p>&#160;</p>
        <p>For this example:</p>
        <p>&#160;</p>
        <p><u>Squared ranks approximate equality of variance test (2 sample)</u>
        </p>
        <p>&#160;</p>
        <p>z = 2.327331</p>
        <p>Two tailed P = .0199</p>
        <p>One tailed P = .01</p>
        <p>&#160;</p>
        <p>Here we reject the null hypothesis that the samples are from identical distributions (except for possibly different means) and we infer a statistically significant difference between the variances.</p>
        <p>&#160;</p>
        <p><a href="../basics/p_values.htm">P values</a>
        </p>
    </body>
</html>